{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:21:59.068991200Z",
     "start_time": "2024-04-21T17:21:59.046986200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:22.480220200Z",
     "start_time": "2024-05-08T18:32:14.291164900Z"
    }
   },
   "id": "42ce37e9a30b8512",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.init as init\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv3d):\n",
    "        init.xavier_uniform_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias.data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:22.500218700Z",
     "start_time": "2024-05-08T18:32:22.483218200Z"
    }
   },
   "id": "d428adbcbe75db2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models import MobileNetV2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:22.515217900Z",
     "start_time": "2024-05-08T18:32:22.497218900Z"
    }
   },
   "id": "e3a201f479e554f1",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:22.528224900Z",
     "start_time": "2024-05-08T18:32:22.512218800Z"
    }
   },
   "id": "6caf26840575ff14",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:22.542732600Z",
     "start_time": "2024-05-08T18:32:22.529225100Z"
    }
   },
   "id": "b3fe9f1b8e41594b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:22.559733400Z",
     "start_time": "2024-05-08T18:32:22.542732600Z"
    }
   },
   "id": "8eaa724997ac8a00",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "SEQ_LENGTH = 30\n",
    "NUM_WORKERS = 0\n",
    "pos_weight = torch.tensor([1.5]).cuda()\n",
    "name = \"MobileNetV2len30size224w4V4\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:23.246442Z",
     "start_time": "2024-05-08T18:32:23.123421800Z"
    }
   },
   "id": "7c09208ce8a5f010",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = MobileNetV2.get_model(sample_size = IMG_SIZE, num_classes =1, in_channels = SEQ_LENGTH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:23.592914300Z",
     "start_time": "2024-05-08T18:32:23.541915Z"
    }
   },
   "id": "34015308e9246ac7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'{name}.pth', map_location=torch.device('cpu')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:23.891978400Z",
     "start_time": "2024-05-08T18:32:23.847979500Z"
    }
   },
   "id": "3a61ca1c5958ccc4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model = nn.DataParallel(model).cuda()\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:25.930967300Z",
     "start_time": "2024-05-08T18:32:25.894964100Z"
    }
   },
   "id": "e6cdbdb4649be7be",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'{name}.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:26.415187300Z",
     "start_time": "2024-05-08T18:32:26.400189600Z"
    }
   },
   "id": "fb9aec8f7894d13e",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:26.801611700Z",
     "start_time": "2024-05-08T18:32:26.790613600Z"
    }
   },
   "id": "f8d3d4d05139f2e8",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:27.299589600Z",
     "start_time": "2024-05-08T18:32:27.285590600Z"
    }
   },
   "id": "bf1f0111169b780e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def augment_video(video_tensor):\n",
    "    flip = random.random() > 0.5\n",
    "    rotation_degree = random.uniform(-15, 15)\n",
    "    grayscale = True  # Всегда делаем изображение черно-белым\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(rotation_degree, rotation_degree)),\n",
    "        transforms.Grayscale(num_output_channels=1) if grayscale else transforms.Lambda(lambda x: x)\n",
    "    ])\n",
    "\n",
    "    augmented_video = transform(video_tensor)\n",
    "\n",
    "    if flip:\n",
    "        augmented_video = torch.flip(augmented_video, [-1])\n",
    "\n",
    "    return augmented_video\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:27.736663500Z",
     "start_time": "2024-05-08T18:32:27.723657600Z"
    }
   },
   "id": "a4aaabfdeec4bbfb",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path=\"\", df_path=\"train.csv\", img_size=224, SEQ_LENGTH=15, transform=None):\n",
    "        self.SEQ_LENGTH = SEQ_LENGTH\n",
    "        self.root_path = root_path\n",
    "        self.img_size = img_size\n",
    "        df = pd.read_csv(df_path)\n",
    "        self.video_paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.transform = transform\n",
    "        unique_labels = sorted(set(self.labels))\n",
    "        print(unique_labels)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cap = cv2.VideoCapture(self.video_paths[idx])\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frames = []\n",
    "        if total_frames >= self.SEQ_LENGTH:\n",
    "            frame_indices = np.linspace(0, total_frames - 1, self.SEQ_LENGTH, dtype=int)\n",
    "        else:\n",
    "            frame_indices = np.tile(np.arange(total_frames), self.SEQ_LENGTH // total_frames + 1)[:self.SEQ_LENGTH]\n",
    "\n",
    "        for i in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            #\n",
    "            frame_sum = np.sum(frame, axis = 2)\n",
    "            y_idx, x_idx = np.where(frame_sum>0)\n",
    "            if len(y_idx) == 0 and len(x_idx) == 0:\n",
    "                return self.__getitem__(idx-1)\n",
    "            y_min, y_max = y_idx.min(), y_idx.max()\n",
    "            x_min, x_max = x_idx.min(), x_idx.max()\n",
    "            \n",
    "            cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "            h, w, _ = cropped_frame.shape\n",
    "            \n",
    "            if h>w:\n",
    "                pad = int((h-w)/2)\n",
    "                padded_frame = np.pad(cropped_frame, ((0,0), (pad,pad), (0,0)))\n",
    "            else:\n",
    "                pad = int((w-h)/2)\n",
    "                padded_frame = np.pad(cropped_frame, ((pad,pad), (0,0), (0,0)))\n",
    "            \n",
    "            \n",
    "            frame_tensor = self.transform(padded_frame).unsqueeze(0)\n",
    "            frames.append(frame_tensor)\n",
    "\n",
    "        while len(frames) < self.SEQ_LENGTH:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        frames_tensor = torch.cat(frames, dim=0)\n",
    "        frames_tensor = augment_video(frames_tensor)\n",
    "        #frames_tensor = frames_tensor.squeeze(1)\n",
    "        #frames_tensor = frames_tensor.permute(1,0,2)\n",
    "        #print(frames_tensor.shape)\n",
    "        return frames_tensor, self.label_to_idx[self.labels[idx]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:28.224783100Z",
     "start_time": "2024-05-08T18:32:28.200781100Z"
    }
   },
   "id": "cf3b9119d96b9d45",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:28.660021300Z",
     "start_time": "2024-05-08T18:32:28.641022400Z"
    }
   },
   "id": "9dcd6fbc6233cc32",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_violence', 'violence']\n",
      "['not_violence', 'violence']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(df_path=\"train.csv\", transform=transform, SEQ_LENGTH = SEQ_LENGTH)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_dataset = CustomDataset(df_path=\"test.csv\", transform=transform,  SEQ_LENGTH = SEQ_LENGTH)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:29.041242500Z",
     "start_time": "2024-05-08T18:32:29.002725800Z"
    }
   },
   "id": "f3e9f605a31b4577",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = train_dataset[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:31.441703200Z",
     "start_time": "2024-05-08T18:32:30.781091600Z"
    }
   },
   "id": "21fa8484494210e3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([30, 1, 224, 224])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:31.903781Z",
     "start_time": "2024-05-08T18:32:31.877785400Z"
    }
   },
   "id": "a69337b18cede01e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model = nn.DataParallel(model).cuda()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T18:32:32.954150Z",
     "start_time": "2024-05-08T18:32:32.936084300Z"
    }
   },
   "id": "79a1038a5df4fe65",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.0730140 accuracy: 0.794 Precision: 0.500 Recall: 0.500 F1: 0.500\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from torch.utils.tensorboard import SummaryWriter  # Добавлено\n",
    "\n",
    "open(f'{name}.log', 'w').close()\n",
    "logging.basicConfig(filename=f'{name}.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "best_valid_loss = 0\n",
    "\n",
    "# Инициализация SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()  # Применяем пороговую функцию для бинарной классификации\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        if i % 10 == 9:\n",
    "            precision = precision_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "            recall = recall_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "            f1 = f1_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "            print('[%d, %5d] loss: %.7f accuracy: %.3f Precision: %.3f Recall: %.3f F1: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, correct / total, precision, recall, f1))\n",
    "            logging.info('[%d, %5d] loss: %.7f accuracy: %.3f Precision: %.3f Recall: %.3f F1: %.3f' %\n",
    "                         (epoch + 1, i + 1, running_loss / 100, correct / total, precision, recall, f1))\n",
    "            # Запись данных в TensorBoard\n",
    "            writer.add_scalar('Training Loss', running_loss / 100, epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Training Accuracy', correct / total, epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Training Precision', precision, epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Training Recall', recall, epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Training F1', f1, epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()  # Применяем пороговую функцию для бинарной классификации\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        precision = precision_score(all_labels, all_predictions)\n",
    "        recall = recall_score(all_labels, all_predictions)\n",
    "        f1 = f1_score(all_labels, all_predictions)\n",
    "        confusion = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "        # Запись данных в TensorBoard после валидации\n",
    "        writer.add_scalar('Validation Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Validation Precision', precision, epoch)\n",
    "        writer.add_scalar('Validation Recall', recall, epoch)\n",
    "        writer.add_scalar('Validation F1', f1, epoch)\n",
    "\n",
    "        # Вывод F1-меры, аккуратности и матрицы ошибок\n",
    "        logging.info('Accuracy: %.3f' % accuracy)\n",
    "        logging.info('Precision: %.3f' % precision)\n",
    "        logging.info('Recall: %.3f' % recall)\n",
    "        logging.info('F1 Score: %.3f' % f1)\n",
    "        logging.info('Confusion Matrix:\\n %s' % confusion)\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        print('Precision: %.3f' % precision)\n",
    "        print('Recall: %.3f' % recall)\n",
    "        print('F1 Score: %.3f' % f1)\n",
    "        print('Confusion Matrix:\\n', confusion)\n",
    "\n",
    "        if f1 > best_valid_loss:\n",
    "            best_valid_loss = f1\n",
    "            torch.save(model.state_dict(), f'{name}.pth')\n",
    "            logging.info('Model saved with accuracy: %.3f' % (accuracy))\n",
    "            print('Model saved with accuracy: %.3f' % (accuracy))\n",
    "\n",
    "# Закрытие SummaryWriter\n",
    "writer.close()\n",
    "\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T18:32:33.714666700Z"
    }
   },
   "id": "b243e79427b2e2c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'last{23}.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T08:29:58.229009500Z",
     "start_time": "2024-04-22T08:29:58.180009500Z"
    }
   },
   "id": "80f9b8a945b814bc",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dba8996c0b7953a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
