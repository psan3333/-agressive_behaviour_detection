{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6LtIHnHVxmQd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 13:38:07.239461: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-16 13:38:07.286213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {'notviolence': 0.6802103250478011, 'violence': 1.8872679045092837}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка CSV-файла\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Подсчет количества меток каждого класса\n",
    "class_counts = df['label'].value_counts()\n",
    "\n",
    "# Вычисление весов для каждого класса\n",
    "total_samples = len(df)\n",
    "class_weights = {}\n",
    "for class_label, count in class_counts.items():\n",
    "    weight = total_samples / (len(class_counts) * count)\n",
    "    class_weights[class_label] = weight\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Возможно нужно подбирать гиперпаораметры \n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 640, 640])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# Функция для аугментации видео\n",
    "def augment_video(video_tensor):\n",
    "    # Создаем случайные значения для всех трансформаций\n",
    "    flip = random.random() > 0.5\n",
    "    rotation_degree = random.uniform(-15, 15)\n",
    "    grayscale = random.random() > 0.5\n",
    "\n",
    "    # Определяем трансформации\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(rotation_degree, rotation_degree)),\n",
    "        transforms.Grayscale(num_output_channels=3) if grayscale else transforms.Lambda(lambda x: x)\n",
    "    ])\n",
    "\n",
    "    # Применяем трансформации к каждому кадру видео\n",
    "    augmented_frames = []\n",
    "    for frame in video_tensor:\n",
    "        augmented_frame = transform(frame)\n",
    "        if flip:\n",
    "            augmented_frame = transforms.functional.hflip(augmented_frame)\n",
    "        augmented_frames.append(augmented_frame)\n",
    "\n",
    "    # Преобразуем список кадров в тензор\n",
    "    augmented_video = torch.stack(augmented_frames)\n",
    "\n",
    "    return augmented_video\n",
    "\n",
    "# Пример использования\n",
    "# Предположим, что video_tensor - это ваш входной тензор размерности [len, 3, 640, 640]\n",
    "# Создадим случайный тензор для демонстрации\n",
    "video_tensor = torch.randn(5, 3, 640, 640)\n",
    "\n",
    "# Вызываем функцию аугментации\n",
    "augmented_video = augment_video(video_tensor)\n",
    "\n",
    "# Результат - аугментированный тензор\n",
    "print(augmented_video.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path=\"\", df_path=\"train.csv\", img_size=224, SEQ_LENGTH=10, transform=None):\n",
    "        self.SEQ_LENGTH = SEQ_LENGTH\n",
    "        self.root_path = root_path\n",
    "        self.img_size = img_size\n",
    "        df = pd.read_csv(df_path)\n",
    "        self.video_paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.transform = transform\n",
    "        unique_labels = sorted(set(self.labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cap = cv2.VideoCapture(self.video_paths[idx])\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frames = []\n",
    "        if total_frames >= self.SEQ_LENGTH:\n",
    "            frame_indices = np.linspace(0, total_frames - 1, self.SEQ_LENGTH, dtype=int)\n",
    "        else:\n",
    "            frame_indices = np.tile(np.arange(total_frames), self.SEQ_LENGTH // total_frames + 1)[:self.SEQ_LENGTH]\n",
    "\n",
    "        for i in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            #\n",
    "            frame_sum = np.sum(frame, axis = 2)\n",
    "            y_idx, x_idx = np.where(frame_sum>0)\n",
    "            #print(y_idx.shape, x_idx.shape)\n",
    "            if len(y_idx) == 0 and len(x_idx) == 0:\n",
    "                print(f\"({idx}\")\n",
    "                return self.__getitem__(idx-1)\n",
    "            y_min, y_max = y_idx.min(), y_idx.max()\n",
    "            x_min, x_max = x_idx.min(), x_idx.max()\n",
    "            \n",
    "            cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
    "            h, w, _ = cropped_frame.shape\n",
    "            \n",
    "            if h>w:\n",
    "                pad = int((h-w)/2)\n",
    "                padded_frame = np.pad(cropped_frame, ((0,0), (pad,pad), (0,0)))\n",
    "            else:\n",
    "                pad = int((w-h)/2)\n",
    "                padded_frame = np.pad(cropped_frame, ((pad,pad), (0,0), (0,0)))\n",
    "            \n",
    "            #\n",
    "            frame_tensor = self.transform(padded_frame).unsqueeze(0)\n",
    "            frames.append(frame_tensor)\n",
    "\n",
    "        while len(frames) < self.SEQ_LENGTH:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        frames_tensor = torch.cat(frames, dim=0)\n",
    "        frames_tensor = augment_video(frames_tensor)\n",
    "        return frames_tensor, self.label_to_idx[self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_path=\"train.csv\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=10)\n",
    "test_dataset = CustomDataset(df_path=\"test.csv\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mCRVKIWexmQe"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self, num_classes):\n",
    "    super().__init__()\n",
    "    self.model = torchvision.models.video.swin3d_t()\n",
    "    self.fc1 = nn.Linear(400, 100)\n",
    "    self.fc2 = nn.Linear(100, num_classes)\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.softmax(x)\n",
    "    return x\n",
    "# model = torchvision.models.video.swin3d_t().to(device)\n",
    "\n",
    "model = Model(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BT4lNWsTxmQf",
    "outputId": "36df5eaf-9d54-4141-92d6-afc8555f27ac"
   },
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model, device_ids = [ 0, 1, 2, 3]).cuda()\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, eps=1e-08, weight_decay=0.0001)\n",
    "class_weights_tensor = torch.tensor(list(class_weights.values())).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxrIfRd7xmQg",
    "outputId": "842bb941-97b5-470b-ca31-f4235710db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.0616286 accuracy: 0.675\n",
      "[1,    20] loss: 0.0550762 accuracy: 0.762\n",
      "[1,    30] loss: 0.0600762 accuracy: 0.713\n",
      "[1,    40] loss: 0.0550762 accuracy: 0.762\n",
      "[1,    50] loss: 0.0650762 accuracy: 0.662\n",
      "[1,    60] loss: 0.0538262 accuracy: 0.775\n",
      "[1,    70] loss: 0.0550762 accuracy: 0.762\n",
      "[1,    80] loss: 0.0588262 accuracy: 0.725\n",
      "[1,    90] loss: 0.0575762 accuracy: 0.738\n",
      "[1,   100] loss: 0.0638228 accuracy: 0.675\n",
      "[1,   110] loss: 0.0538389 accuracy: 0.775\n",
      "[1,   120] loss: 0.0563262 accuracy: 0.750\n",
      "[1,   130] loss: 0.0525763 accuracy: 0.787\n",
      "[1,   140] loss: 0.0550772 accuracy: 0.762\n",
      "[1,   150] loss: 0.0640020 accuracy: 0.675\n",
      "[1,   160] loss: 0.0588262 accuracy: 0.725\n",
      "[1,   170] loss: 0.0550762 accuracy: 0.762\n",
      "(3\n",
      "Accuracy: 0.772\n",
      "F1 Score: 0.000\n",
      "Confusion Matrix:\n",
      " [[275   0]\n",
      " [ 81   0]]\n",
      "Model saved with accuracy: 0.772\n",
      "[2,    10] loss: 0.0538262 accuracy: 0.775\n",
      "[2,    20] loss: 0.0575762 accuracy: 0.738\n",
      "[2,    30] loss: 0.0588262 accuracy: 0.725\n",
      "[2,    40] loss: 0.0550764 accuracy: 0.762\n",
      "[2,    50] loss: 0.0563264 accuracy: 0.750\n",
      "[2,    60] loss: 0.0550768 accuracy: 0.762\n",
      "[2,    70] loss: 0.0538273 accuracy: 0.775\n",
      "[2,    80] loss: 0.0650744 accuracy: 0.662\n",
      "[2,    90] loss: 0.0588291 accuracy: 0.725\n",
      "[2,   100] loss: 0.0563313 accuracy: 0.750\n",
      "[2,   110] loss: 0.0600715 accuracy: 0.713\n",
      "[2,   120] loss: 0.0575870 accuracy: 0.738\n",
      "[2,   130] loss: 0.0575988 accuracy: 0.738\n",
      "[2,   140] loss: 0.0706237 accuracy: 0.600\n",
      "[2,   150] loss: 0.0604909 accuracy: 0.713\n",
      "[2,   160] loss: 0.0525762 accuracy: 0.787\n",
      "[2,   170] loss: 0.0613262 accuracy: 0.700\n",
      "(3\n",
      "Accuracy: 0.772\n",
      "F1 Score: 0.000\n",
      "Confusion Matrix:\n",
      " [[275   0]\n",
      " [ 81   0]]\n",
      "[3,    10] loss: 0.0625762 accuracy: 0.688\n",
      "[3,    20] loss: 0.0500762 accuracy: 0.812\n",
      "[3,    30] loss: 0.0550763 accuracy: 0.762\n",
      "[3,    40] loss: 0.0563269 accuracy: 0.750\n",
      "[3,    50] loss: 0.0550772 accuracy: 0.762\n",
      "[3,    60] loss: 0.0525827 accuracy: 0.787\n",
      "[3,    70] loss: 0.0638184 accuracy: 0.675\n",
      "[3,    80] loss: 0.0551007 accuracy: 0.762\n",
      "[3,    90] loss: 0.0525810 accuracy: 0.787\n",
      "[3,   100] loss: 0.0613251 accuracy: 0.700\n",
      "[3,   110] loss: 0.0550899 accuracy: 0.762\n",
      "[3,   120] loss: 0.0575797 accuracy: 0.738\n",
      "[3,   130] loss: 0.0663100 accuracy: 0.650\n",
      "[3,   140] loss: 0.0526119 accuracy: 0.787\n",
      "[3,   150] loss: 0.0662945 accuracy: 0.650\n",
      "[3,   160] loss: 0.0613297 accuracy: 0.700\n",
      "[3,   170] loss: 0.0566408 accuracy: 0.750\n",
      "(3\n",
      "Accuracy: 0.772\n",
      "F1 Score: 0.000\n",
      "Confusion Matrix:\n",
      " [[275   0]\n",
      " [ 81   0]]\n",
      "[4,    10] loss: 0.0563424 accuracy: 0.750\n",
      "[4,    20] loss: 0.0513274 accuracy: 0.800\n",
      "[4,    30] loss: 0.0550769 accuracy: 0.762\n",
      "[4,    40] loss: 0.0538281 accuracy: 0.775\n",
      "[4,    50] loss: 0.0538310 accuracy: 0.775\n",
      "[4,    60] loss: 0.0613245 accuracy: 0.700\n",
      "[4,    70] loss: 0.0613203 accuracy: 0.700\n",
      "[4,    80] loss: 0.0615015 accuracy: 0.700\n",
      "[4,    90] loss: 0.0563264 accuracy: 0.750\n",
      "[4,   100] loss: 0.0538275 accuracy: 0.775\n",
      "[4,   110] loss: 0.0613222 accuracy: 0.700\n",
      "[4,   120] loss: 0.0588284 accuracy: 0.725\n",
      "[4,   130] loss: 0.0588328 accuracy: 0.725\n",
      "[4,   140] loss: 0.0613191 accuracy: 0.700\n",
      "[4,   150] loss: 0.0625575 accuracy: 0.688\n",
      "[4,   160] loss: 0.0526336 accuracy: 0.787\n",
      "[4,   170] loss: 0.0638028 accuracy: 0.675\n",
      "(3\n",
      "Accuracy: 0.772\n",
      "F1 Score: 0.000\n",
      "Confusion Matrix:\n",
      " [[275   0]\n",
      " [ 81   0]]\n",
      "[5,    10] loss: 0.0613031 accuracy: 0.700\n",
      "[5,    20] loss: 0.0657302 accuracy: 0.650\n",
      "[5,    30] loss: 0.0536364 accuracy: 0.800\n",
      "[5,    40] loss: 0.0713200 accuracy: 0.600\n",
      "[5,    50] loss: 0.0463286 accuracy: 0.850\n",
      "[5,    60] loss: 0.0500787 accuracy: 0.812\n",
      "[5,    70] loss: 0.0550814 accuracy: 0.762\n",
      "[5,    80] loss: 0.0575767 accuracy: 0.738\n",
      "[5,    90] loss: 0.0550764 accuracy: 0.762\n",
      "[5,   100] loss: 0.0463300 accuracy: 0.850\n",
      "[5,   110] loss: 0.0463308 accuracy: 0.850\n",
      "[5,   120] loss: 0.0663227 accuracy: 0.650\n",
      "[5,   130] loss: 0.0638301 accuracy: 0.675\n",
      "[5,   140] loss: 0.0600738 accuracy: 0.713\n",
      "[5,   150] loss: 0.0588241 accuracy: 0.725\n",
      "[5,   160] loss: 0.0662812 accuracy: 0.650\n",
      "[5,   170] loss: 0.0698778 accuracy: 0.613\n",
      "(3\n",
      "Accuracy: 0.772\n",
      "F1 Score: 0.000\n",
      "Confusion Matrix:\n",
      " [[275   0]\n",
      " [ 81   0]]\n",
      "[6,    10] loss: 0.0475762 accuracy: 0.838\n",
      "[6,    20] loss: 0.0513262 accuracy: 0.800\n",
      "[6,    30] loss: 0.0538262 accuracy: 0.775\n",
      "[6,    40] loss: 0.0563262 accuracy: 0.750\n",
      "[6,    50] loss: 0.0538262 accuracy: 0.775\n",
      "[6,    60] loss: 0.0600759 accuracy: 0.713\n",
      "[6,    70] loss: 0.0563265 accuracy: 0.750\n",
      "[6,    80] loss: 0.0658945 accuracy: 0.662\n",
      "[6,    90] loss: 0.0671561 accuracy: 0.613\n",
      "[6,   100] loss: 0.0649858 accuracy: 0.662\n",
      "[6,   110] loss: 0.0600719 accuracy: 0.713\n",
      "[6,   120] loss: 0.0652946 accuracy: 0.637\n",
      "[6,   130] loss: 0.0588262 accuracy: 0.725\n",
      "[6,   140] loss: 0.0613262 accuracy: 0.700\n",
      "[6,   150] loss: 0.0575762 accuracy: 0.738\n",
      "[6,   160] loss: 0.0563262 accuracy: 0.750\n",
      "[6,   170] loss: 0.0575762 accuracy: 0.738\n",
      "(3\n",
      "Accuracy: 0.772\n",
      "F1 Score: 0.000\n",
      "Confusion Matrix:\n",
      " [[275   0]\n",
      " [ 81   0]]\n",
      "[7,    10] loss: 0.0563262 accuracy: 0.750\n",
      "[7,    20] loss: 0.0563262 accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "open('sgd_training_with_seq_length10.log', 'w').close()\n",
    "logging.basicConfig(filename='sgd_training_with_seq_length10.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.permute((0, 2, 1, 3, 4)) # torch.Size([8, 10, 3, 640, 640])\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if i % 10 == 9:  \n",
    "            print('[%d, %5d] loss: %.7f accuracy: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, correct / total))\n",
    "            logging.info('[%d, %5d] loss: %.7f accuracy: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, correct / total))\n",
    "            # TODO добавить данные в борд \n",
    "            writer.add_scalar('Training Loss', running_loss / 100, epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Training Accuracy', correct / total, epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.permute((0, 2, 1, 3, 4)) # torch.Size([8, 10, 3, 640, 640])\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1 = f1_score(all_labels, all_predictions)\n",
    "        confusion = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        # Вывод F1-меры, аккуратности и матрицы ошибок\n",
    "        logging.info('Accuracy: %.3f' % accuracy)\n",
    "        logging.info('F1 Score: %.3f' % f1)\n",
    "        logging.info('Confusion Matrix:\\n %s' % confusion)\n",
    "        print('Accuracy: %.3f' % accuracy)\n",
    "        print('F1 Score: %.3f' % f1)\n",
    "        print('Confusion Matrix:\\n', confusion)\n",
    "        \n",
    "        if f1 < best_valid_loss:\n",
    "            best_valid_loss = f1\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            logging.info('Model saved with accuracy: %.3f' % (accuracy))\n",
    "            print('Model saved with accuracy: %.3f' % (accuracy))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
