{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c877eaa911557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T04:49:12.307677900Z",
     "start_time": "2024-02-22T04:49:12.293332700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3b97eb5678e677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:27.552837400Z",
     "start_time": "2024-02-22T05:14:25.596906600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2024-02-23 10:48:09.201324: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-23 10:48:09.248733: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c76b428cf82f94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:27.582318600Z",
     "start_time": "2024-02-22T05:14:27.552837400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32909051b7c219f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:27.597603300Z",
     "start_time": "2024-02-22T05:14:27.582318600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#TODO Возможно нужно подбирать гиперпаораметры \n",
    "IMG_SIZE = 255\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f6b1326f1cbe0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:28.541149100Z",
     "start_time": "2024-02-22T05:14:28.525799700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    #transforms.Resize((224, 224)),  # Опционально, в зависимости от ваших требований\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c70e6fde00d76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:28.773903Z",
     "start_time": "2024-02-22T05:14:28.763606700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path=\"\", df_path=\"train.csv\", img_size=224, SEQ_LENGTH=100, transform=None):\n",
    "        self.SEQ_LENGTH = SEQ_LENGTH\n",
    "        self.root_path = root_path\n",
    "        self.img_size = img_size\n",
    "        df = pd.read_csv(df_path)\n",
    "        self.video_paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.transform = transform\n",
    "        unique_labels = sorted(set(self.labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cap = cv2.VideoCapture(self.video_paths[idx])\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frames = []\n",
    "        if total_frames >= self.SEQ_LENGTH:\n",
    "            frame_indices = np.linspace(0, total_frames - 1, self.SEQ_LENGTH, dtype=int)\n",
    "        else:\n",
    "            frame_indices = np.tile(np.arange(total_frames), self.SEQ_LENGTH // total_frames + 1)[:self.SEQ_LENGTH]\n",
    "\n",
    "        for i in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_tensor = self.transform(frame).unsqueeze(0).to(device)\n",
    "            frames.append(frame_tensor)\n",
    "\n",
    "        while len(frames) < self.SEQ_LENGTH:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        frames_tensor = torch.cat(frames, dim=0)\n",
    "        frames_tensor = frames_tensor.permute(1,0,2,3)\n",
    "        return frames_tensor, self.label_to_idx[self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b7e97e3cdc4c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:29.215837500Z",
     "start_time": "2024-02-22T05:14:29.204602900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_path=\"train.csv\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_dataset = CustomDataset(df_path=\"test.csv\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c374d2586f3b23a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:29.463161400Z",
     "start_time": "2024-02-22T05:14:29.452976700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1707b000e046e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:54.969477300Z",
     "start_time": "2024-02-22T05:14:54.673196Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Загрузка предварительно обученной модели 3D ResNet\n",
    "#model = torchvision.models.video.r3d_18(num_classes=1).to(device)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Пример модификации модели\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Пример модификации модели\n",
    "class ModifiedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedModel, self).__init__()\n",
    "        self.base_model = torchvision.models.video.r3d_18(num_classes=512)\n",
    "        \n",
    "        self.base_model.fc = nn.Identity()  # Заменяем последний FC слой на Identity, чтобы избежать ошибки с числом классов\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.fc_layers(x)\n",
    "        x = torch.sigmoid(x)  # Применяем сигмоиду к выходу\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = ModifiedModel()\n",
    "model = nn.DataParallel(model, device_ids = [ 0, 1, 2, 3]).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765e34a4f4e01ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:14:54.991981300Z",
     "start_time": "2024-02-22T05:14:54.973614100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c437f022cfd3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:16:01.575903400Z",
     "start_time": "2024-02-22T05:14:55.415920600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/475, Loss: 0.3631\n",
      "Epoch 1, Batch 20/475, Loss: 0.0730\n",
      "Epoch 1, Batch 30/475, Loss: 0.0688\n",
      "Epoch 1, Batch 40/475, Loss: 0.0771\n",
      "Epoch 1, Batch 50/475, Loss: 0.0687\n",
      "Epoch 1, Batch 60/475, Loss: 0.0677\n",
      "Epoch 1, Batch 70/475, Loss: 0.0632\n",
      "Epoch 1, Batch 80/475, Loss: 0.0711\n",
      "Epoch 1, Batch 90/475, Loss: 0.0703\n",
      "Epoch 1, Batch 100/475, Loss: 0.0698\n",
      "Epoch 1, Batch 110/475, Loss: 0.0694\n",
      "Epoch 1, Batch 120/475, Loss: 0.0691\n",
      "Epoch 1, Batch 130/475, Loss: 0.0703\n",
      "Epoch 1, Batch 140/475, Loss: 0.0696\n",
      "Epoch 1, Batch 150/475, Loss: 0.0689\n",
      "Epoch 1, Batch 160/475, Loss: 0.0700\n",
      "Epoch 1, Batch 170/475, Loss: 0.0697\n",
      "Epoch 1, Batch 180/475, Loss: 0.0689\n",
      "Epoch 1, Batch 190/475, Loss: 0.0687\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Конфигурация логирования\n",
    "logging.basicConfig(filename='hight.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Переменная для хранения наивысшей точности\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Переводим модель в режим обучения\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Обнуляем градиенты параметров\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Прямой проход: вычисляем предсказанные значения\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Вычисляем потери\n",
    "        loss = criterion(outputs, target.float().view(-1, 1))\n",
    "\n",
    "        # Обратное распространение и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Считаем общие потери\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Выводим промежуточные результаты в терминал\n",
    "        if batch_idx % 10 == 9:  # Выводим каждые 100 батчей\n",
    "            print(f'Epoch {epoch + 1}, Batch {batch_idx + 1}/{len(train_loader)}, Loss: {running_loss / 100:.4f}')\n",
    "            logging.info(f'Epoch {epoch + 1}, Batch {batch_idx + 1}/{len(train_loader)}, Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Оценка модели после каждой эпохи\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, target.float().view(-1, 1)).item()\n",
    "            predicted = torch.round(outputs)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target.float().view(-1, 1)).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'Test Loss: {test_loss / len(test_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    logging.info(f'Test Loss: {test_loss / len(test_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # Сохраняем модель, если достигнута лучшая точность\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), '256_best_model.pth')\n",
    "        logging.info('Best model saved.')\n",
    "\n",
    "logging.info('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213ead3dd716672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T05:00:05.196507Z",
     "start_time": "2024-02-22T05:00:05.182163700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bb521b236eb73",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
