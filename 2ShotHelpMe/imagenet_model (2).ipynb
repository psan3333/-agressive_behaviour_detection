{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac4efe1-ef2c-4bab-9970-ec07c281a065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117f3db2-f58e-4bf0-b5d4-e455409410a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7af4a34-3819-44fc-a75f-a7290dbfef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, class_name_in_int, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.class_name_in_int = class_name_in_int\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get list of file paths and tags\n",
    "        self.file_paths = []\n",
    "        self.tags = []\n",
    "        for class_name in os.listdir(self.img_dir):\n",
    "            class_dir = os.path.join(self.img_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            tag = class_name_in_int.get(class_name)\n",
    "            if tag is None:\n",
    "                continue\n",
    "                \n",
    "            class_file_paths = glob.glob(os.path.join(class_dir, \"*.jpg\"))\n",
    "            self.file_paths.extend(class_file_paths)\n",
    "            self.tags.extend([tag] * len(class_file_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tags)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        tag = self.tags[idx]\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(tag, dtype=torch.long)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1c8899-4ae4-44c3-8bc7-2bb617132c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"imagenet1k\"\n",
    "\n",
    "class_name_in_int = {}\n",
    "class_name_in_str = {}\n",
    "i = 0\n",
    "for classes_name in os.listdir(path):\n",
    "    if classes_name.endswith('.ipynb_checkpoints'):\n",
    "        continue\n",
    "    class_name = classes_name.split('_', 1)[-1]\n",
    "    class_name_in_int[classes_name] = i\n",
    "    class_name_in_str[i] = class_name\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa7130e-e3eb-4abb-bcae-2ec4edc8053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(path, class_name_in_int, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a92a944-df14-4b94-9524-6893cfd857df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab6f61e-0d93-42cd-b532-2b93fc92c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(path, class_name_in_int, transform=transform)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers = 16)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers = 16)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d864444-ba79-45d8-a796-efdebda4581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tipa_ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes = 1000):\n",
    "        super(Tipa_ResNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        #Part 1\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=11, padding = 5)\n",
    "        self.conv_layer1_batch = nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, padding = 1)\n",
    "        self.conv_layer2_batch = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding = 1)\n",
    "        self.conv_layer3_batch = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1, padding = 0)\n",
    "        self.conv_layer4_batch = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.conv_layer5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=17, padding = 8)\n",
    "        self.conv_layer5_batch = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = 1)\n",
    "        self.conv_layer6_batch = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer7 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding = 1)\n",
    "        self.conv_layer7_batch = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer8 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, padding = 0)\n",
    "        self.conv_layer8_batch = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.conv_layer9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=23, padding = 11)\n",
    "        self.conv_layer9_batch = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer10 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding = 1)\n",
    "        self.conv_layer10_batch = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer11 = nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=3, padding = 1)\n",
    "        self.conv_layer11_batch = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer12 = nn.Conv2d(in_channels=2048, out_channels=2048, kernel_size=1, padding = 0)\n",
    "        self.conv_layer12_batch = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        #Part 2\n",
    "        self.conv_layer13 = nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=11, padding = 5)\n",
    "        self.conv_layer13_batch = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer14 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding = 1)\n",
    "        self.conv_layer14_batch = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer15 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=3, padding = 1)\n",
    "        self.conv_layer15_batch = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer16 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding = 0)\n",
    "        self.conv_layer16_batch = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.conv_layer17 = nn.Conv2d(in_channels=128, out_channels=32, kernel_size=17, padding = 8)\n",
    "        self.conv_layer17_batch = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer18 = nn.Conv2d(in_channels=32, out_channels=8, kernel_size=3, padding = 1)\n",
    "        self.conv_layer18_batch = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer19 = nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, padding = 1)\n",
    "        self.conv_layer19_batch = nn.BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer20 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, padding = 0)\n",
    "        self.conv_layer20_batch = nn.BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        #Part 3\n",
    "        self.conv_layer21 = nn.Conv2d(in_channels=1, out_channels= 8, kernel_size=23, padding = 11)\n",
    "        self.conv_layer21_batch = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer22 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding = 1)\n",
    "        self.conv_layer22_batch = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv_layer23 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding = 1)\n",
    "        self.conv_layer23_batch = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        self.fc_layer1 = nn.Linear(64, 128)\n",
    "        self.fc_layer2 = nn.Linear(128, 256)\n",
    "        self.fc_layer3 = nn.Linear(256, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        BATCH_SIZE = x.shape[0]\n",
    "        IMG_SIZE = x.shape[3]\n",
    "        #Part1\n",
    "        x = self.relu(self.conv_layer1_batch(self.conv_layer1(x))) if x.size(0) > 1 else self.relu(self.conv_layer1(x))\n",
    "        x = self.relu(self.conv_layer2_batch(self.conv_layer2(x))) if x.size(0) > 1 else self.relu(self.conv_layer2(x))\n",
    "        x = self.relu(self.conv_layer3_batch(self.conv_layer3(x))) if x.size(0) > 1 else self.relu(self.conv_layer3(x))\n",
    "        x2 = self.relu(self.conv_layer4_batch(self.conv_layer4(x))) if x.size(0) > 1 else self.relu(self.conv_layer4(x))\n",
    "        x = x + x2\n",
    "        \n",
    "        x = self.relu(self.conv_layer5_batch(self.conv_layer5(x))) if x.size(0) > 1 else self.relu(self.conv_layer5(x))\n",
    "        x = self.relu(self.conv_layer6_batch(self.conv_layer6(x))) if x.size(0) > 1 else self.relu(self.conv_layer6(x))\n",
    "        x = self.relu(self.conv_layer7_batch(self.conv_layer7(x))) if x.size(0) > 1 else self.relu(self.conv_layer7(x))\n",
    "        x2 = self.relu(self.conv_layer8_batch(self.conv_layer8(x))) if x.size(0) > 1 else self.relu(self.conv_layer8(x))\n",
    "        x = x + x2\n",
    "        \n",
    "        x = self.relu(self.conv_layer9_batch(self.conv_layer9(x))) if x.size(0) > 1 else self.relu(self.conv_layer9(x))\n",
    "        x = self.relu(self.conv_layer10_batch(self.conv_layer10(x))) if x.size(0) > 1 else self.relu(self.conv_layer10(x))\n",
    "        x = self.relu(self.conv_layer11_batch(self.conv_layer11(x))) if x.size(0) > 1 else self.relu(self.conv_layer11(x))\n",
    "        x2 = self.relu(self.conv_layer12_batch(self.conv_layer12(x))) if x.size(0) > 1 else self.relu(self.conv_layer12(x))\n",
    "        x = x + x2\n",
    "        \n",
    "        #Part 2\n",
    "        x = self.relu(self.conv_layer13_batch(self.conv_layer13(x))) if x.size(0) > 1 else self.relu(self.conv_layer13(x))\n",
    "        x = self.relu(self.conv_layer14_batch(self.conv_layer14(x))) if x.size(0) > 1 else self.relu(self.conv_layer14(x))\n",
    "        x = self.relu(self.conv_layer15_batch(self.conv_layer15(x))) if x.size(0) > 1 else self.relu(self.conv_layer15(x))\n",
    "        x2 = self.relu(self.conv_layer16_batch(self.conv_layer16(x))) if x.size(0) > 1 else self.relu(self.conv_layer16(x))\n",
    "        x = x + x2\n",
    "        \n",
    "        x = self.relu(self.conv_layer17_batch(self.conv_layer17(x))) if x.size(0) > 1 else self.relu(self.conv_layer17(x))\n",
    "        x = self.relu(self.conv_layer18_batch(self.conv_layer18(x))) if x.size(0) > 1 else self.relu(self.conv_layer18(x))\n",
    "        x = self.relu(self.conv_layer19_batch(self.conv_layer19(x))) if x.size(0) > 1 else self.relu(self.conv_layer19(x))\n",
    "        x2 = self.relu(self.conv_layer20_batch(self.conv_layer20(x))) if x.size(0) > 1 else self.relu(self.conv_layer20(x))\n",
    "        x = x + x2\n",
    "        \n",
    "        #Part 3\n",
    "        x = self.relu(self.conv_layer21_batch(self.conv_layer21(x))) if x.size(0) > 1 else self.relu(self.conv_layer21(x))\n",
    "        x = self.relu(self.conv_layer22_batch(self.conv_layer22(x))) if x.size(0) > 1 else self.relu(self.conv_layer22(x))\n",
    "        x = self.relu(self.conv_layer23_batch(self.conv_layer23(x))) if x.size(0) > 1 else self.relu(self.conv_layer23(x))\n",
    "\n",
    "        \n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer1(x)\n",
    "        x = self.fc_layer2(x)\n",
    "        x = self.fc_layer3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01042e0b-e42f-4e7d-9cbe-d8720ec46ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_name_in_int)\n",
    "\n",
    "model = Tipa_ResNet(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9f725b-ad2b-40f7-abe9-f20a79dfd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1ba8fd-7796-454f-92f6-190241987760",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.98, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb41f1e-f8d4-4910-9f3f-b13be35b1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10/8750, Loss: 5.5240\n",
      "Epoch 1, Batch 20/8750, Loss: 5.5254\n",
      "Epoch 1, Batch 30/8750, Loss: 5.5277\n",
      "Epoch 1, Batch 40/8750, Loss: 5.5322\n",
      "Epoch 1, Batch 50/8750, Loss: 5.5155\n",
      "Epoch 1, Batch 60/8750, Loss: 5.5334\n",
      "Epoch 1, Batch 70/8750, Loss: 5.5346\n",
      "Epoch 1, Batch 80/8750, Loss: 5.5248\n",
      "Epoch 1, Batch 90/8750, Loss: 5.5224\n",
      "Epoch 1, Batch 100/8750, Loss: 5.5294\n",
      "Epoch 1, Batch 110/8750, Loss: 5.5278\n",
      "Epoch 1, Batch 120/8750, Loss: 5.5113\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "best_model_path = 'best_model_images.pt'\n",
    "\n",
    "open('training.log', 'w').close()\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Обучение модели\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        if i % 10 == 9:  # Выводим каждые 100 батчей\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}/{len(train_loader)}, Loss: {train_loss / 100:.4f}')\n",
    "            train_loss = 0.0\n",
    "        \n",
    "\n",
    "    # Вычисление потерь на обучающем наборе данных\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Валидация модели\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Вычисление потерь на валидационном наборе данных\n",
    "    valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "    # Сохранение лучшей модели\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    # Логирование\n",
    "    logging.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3ee74-b7e5-4b9e-bf27-a6928e86ef8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
