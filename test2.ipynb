{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60b905b-26e1-483a-af95-ed878d603c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /opt/conda/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext) (1.26.3)\n",
      "Requirement already satisfied: torchdata==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torchtext) (0.7.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0->torchtext) (2.2.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.7.1->torchtext) (1.26.18)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.0->torchtext) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.0->torchtext) (1.3.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4951aa39-5f22-4ae7-8c20-73a2caed8ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/pip\", line 6, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
      "    from pip._internal.build_env import get_runnable_pip\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
      "    from pip._internal.cli.spinners import open_spinner\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
      "    from pip._internal.utils.logging import get_indentation\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 29, in <module>\n",
      "    from pip._internal.utils.misc import ensure_dir\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/utils/misc.py\", line 43, in <module>\n",
      "    from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/exceptions.py\", line 18, in <module>\n",
      "    from pip._vendor.requests.models import Request, Response\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/requests/__init__.py\", line 45, in <module>\n",
      "    from .exceptions import RequestsDependencyWarning\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/requests/exceptions.py\", line 9, in <module>\n",
      "    from .compat import JSONDecodeError as CompatJSONDecodeError\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/requests/compat.py\", line 10, in <module>\n",
      "    from pip._vendor import chardet\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/chardet/__init__.py\", line 24, in <module>\n",
      "    from .universaldetector import UniversalDetector\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/chardet/universaldetector.py\", line 52, in <module>\n",
      "    from .sbcsgroupprober import SBCSGroupProber\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/chardet/sbcsgroupprober.py\", line 30, in <module>\n",
      "    from .hebrewprober import HebrewProber\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 676, in _compile_bytecode\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorchvideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d24e4bd-76e2-4732-9e99-a6378e146bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y torchtext -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14e46c-eac3-40d1-a73f-2d3629307886",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c pytorch torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb19e66-cd40-4a39-a2a6-696d3f55e96f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Установите метод запуска перед созданием процесса\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_start_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Создайте процесс или выполните свой код, который вызывает многопроцессорность\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/context.py:247\u001b[0m, in \u001b[0;36mDefaultContext.set_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_start_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[0;32m--> 247\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext has already been set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m force:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Установите метод запуска перед созданием процесса\n",
    "mp.set_start_method('spawn')\n",
    "\n",
    "# Создайте процесс или выполните свой код, который вызывает многопроцессорность\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f82803ec1442d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:28.919114900Z",
     "start_time": "2024-02-21T19:06:23.108513100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2024-02-21 19:29:07.239068: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-21 19:29:07.287265: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import pytorchvideo\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33243288f2eb960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:31.597984200Z",
     "start_time": "2024-02-21T19:06:31.554573700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16deded6dc6f4af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:31.617090300Z",
     "start_time": "2024-02-21T19:06:31.585982100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path=\"\", df_path=\"train.csv\", img_size=224, SEQ_LENGTH=100, transform=None):\n",
    "        self.SEQ_LENGTH = SEQ_LENGTH\n",
    "        self.root_path = root_path\n",
    "        self.img_size = img_size\n",
    "        df = pd.read_csv(df_path)\n",
    "        self.video_paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.transform = transform\n",
    "        unique_labels = sorted(set(self.labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cap = cv2.VideoCapture(self.video_paths[idx])\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frames = []\n",
    "        if total_frames >= self.SEQ_LENGTH:\n",
    "            frame_indices = np.linspace(0, total_frames - 1, self.SEQ_LENGTH, dtype=int)\n",
    "        else:\n",
    "            frame_indices = np.tile(np.arange(total_frames), self.SEQ_LENGTH // total_frames + 1)[:self.SEQ_LENGTH]\n",
    "\n",
    "        for i in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_tensor = self.transform(frame).unsqueeze(0).to(device)\n",
    "            frames.append(frame_tensor)\n",
    "\n",
    "        while len(frames) < self.SEQ_LENGTH:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        frames_tensor = torch.cat(frames, dim=0)\n",
    "        frames_tensor = frames_tensor.permute(1, 0, 2,3)\n",
    "\n",
    "        return frames_tensor, self.label_to_idx[self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92c8e5a24d72f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:31.621000700Z",
     "start_time": "2024-02-21T19:06:31.601982700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9315505232a9fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:31.636026400Z",
     "start_time": "2024-02-21T19:06:31.619005200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#TODO Возможно нужно подбирать гиперпаораметры \n",
    "IMG_SIZE = 255\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 100\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fbc81ed1dc3a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:31.658565600Z",
     "start_time": "2024-02-21T19:06:31.635026400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_path=\"train.csv\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_dataset = CustomDataset(df_path=\"test.csv\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b27e15130eb508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:31.991919500Z",
     "start_time": "2024-02-21T19:06:31.649054900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da53102e44b001a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:32.036839600Z",
     "start_time": "2024-02-21T19:06:31.991919500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pytorchvideo.models.resnet\n",
    "\n",
    "def make_kinetics_resnet():\n",
    "    return pytorchvideo.models.resnet.create_resnet(\n",
    "        input_channel=3, # RGB input from Kinetics\n",
    "        model_depth=50, # For the tutorial let's just use a 50 layer network\n",
    "        model_num_class=2, # Kinetics has 400 classes so we need out final head to align\n",
    "        norm=nn.BatchNorm3d,\n",
    "        activation=nn.ReLU,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c48e2f2e6c6455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:32.053350Z",
     "start_time": "2024-02-21T19:06:32.037839500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pytorchvideo.models.resnet\n",
    "\n",
    "def make_kinetics_resnet():\n",
    "    return pytorchvideo.models.resnet.create_resnet(\n",
    "        input_channel=3, # RGB input from Kinetics\n",
    "        model_depth=50, # For the tutorial let's just use a 50 layer network\n",
    "        model_num_class=1, # Kinetics has 400 classes so we need out final head to align\n",
    "        norm=nn.BatchNorm3d,\n",
    "        activation=nn.ReLU,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f342594f59089cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:32.303240200Z",
     "start_time": "2024-02-21T19:06:32.053350Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = make_kinetics_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5adad7e44124a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:06:37.093494200Z",
     "start_time": "2024-02-21T19:06:32.303240200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model, device_ids = [ 0, 1, 2, 3]).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 10))\n",
    "        running_loss = 0.0\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "    writer.add_scalar('Train Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Train Accuracy', train_acc, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "    writer.add_scalar('Test Loss', test_loss, epoch)\n",
    "    writer.add_scalar('Test Accuracy', test_acc, epoch)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{EPOCHS}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2068be8be8a030",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-21T19:01:13.590608300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorchvideo.models.resnet as resnet\n",
    "\n",
    "def make_kinetics_resnet():\n",
    "    return resnet.create_resnet(\n",
    "        input_channel=3, # RGB input from Kinetics\n",
    "        model_depth=50, # For the tutorial let's just use a 50 layer network\n",
    "        model_num_class=2, # Kinetics has 400 classes so we need our final head to align\n",
    "        norm=nn.BatchNorm3d,\n",
    "        activation=nn.ReLU,\n",
    "    )\n",
    "\n",
    "def get_vector(model, input_shape):\n",
    "    # Создание случайных данных\n",
    "    input_tensor = torch.randn(input_shape)\n",
    "    # Прогон через модель\n",
    "    output = model(input_tensor)\n",
    "    return output\n",
    "\n",
    "model = make_kinetics_resnet()\n",
    "# Пример вызова\n",
    "output_vector = get_vector(model, (2, 3, 8, 224, 224))\n",
    "print(output_vector.shape)  # Результат: torch.Size([2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4612b7631e374f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
