{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:42.147928600Z",
     "start_time": "2024-02-18T14:41:36.684034400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 08:26:23.618416: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-21 08:26:23.665868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf79f9d0e99815d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:42.180546600Z",
     "start_time": "2024-02-18T14:41:42.146931400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1367f206-b478-4dc7-a28a-ddcf3d6fcc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5d0534-c9c5-424f-9e26-b5c1371d4ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3]).to(device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22da2078cd99eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:42.193552400Z",
     "start_time": "2024-02-18T14:41:42.178546700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#TODO Возможно нужно подбирать гиперпаораметры \n",
    "IMG_SIZE = 255\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f7cb155daa7fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:42.210058800Z",
     "start_time": "2024-02-18T14:41:42.194552800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10429c074462445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:44.642877800Z",
     "start_time": "2024-02-18T14:41:44.623876800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path=\"\", df_path=\"train.csv\", img_size=224, SEQ_LENGTH=100, transform=None):\n",
    "        self.SEQ_LENGTH = SEQ_LENGTH\n",
    "        self.root_path = root_path\n",
    "        self.img_size = img_size\n",
    "        df = pd.read_csv(df_path)\n",
    "        self.video_paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.transform = transform\n",
    "        unique_labels = sorted(set(self.labels))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cap = cv2.VideoCapture(self.video_paths[idx])\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frames = []\n",
    "        if total_frames >= self.SEQ_LENGTH:\n",
    "            frame_indices = np.linspace(0, total_frames - 1, self.SEQ_LENGTH, dtype=int)\n",
    "        else:\n",
    "            frame_indices = np.tile(np.arange(total_frames), self.SEQ_LENGTH // total_frames + 1)[:self.SEQ_LENGTH]\n",
    "\n",
    "        for i in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_tensor = self.transform(frame).unsqueeze(0).to(device)\n",
    "            frames.append(frame_tensor)\n",
    "\n",
    "        while len(frames) < self.SEQ_LENGTH:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        frames_tensor = torch.cat(frames, dim=0)\n",
    "\n",
    "        return frames_tensor, self.label_to_idx[self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521c638a823e9536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:45.087502300Z",
     "start_time": "2024-02-18T14:41:45.078504700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_path=\"train.csv\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_dataset = CustomDataset(df_path=\"test.csv\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e375e021bf9168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:45.936916900Z",
     "start_time": "2024-02-18T14:41:45.652800900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01125597335d5bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:46.039424100Z",
     "start_time": "2024-02-18T14:41:46.029422500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CNN_RNN(nn.Module):\n",
    "    def __init__(self, num_classes, rnn_hidden_size=256, rnn_num_layers=2):\n",
    "        super(CNN_RNN, self).__init__()\n",
    "        #ResNet-50, вообще, вроде есть модели обученные на людях.....\n",
    "        #TODO найти норм модель \n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # заменяем последний слой на слой с выходом размерности 512\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        # LSTM\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=512, hidden_size=rnn_hidden_size, num_layers=rnn_num_layers, batch_first=True)\n",
    "        # полносвязанный слой для классификации\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Прогоняем resNetку \n",
    "        batch_size, seq_length, _, h, w = x.size()\n",
    "        x = x.view(batch_size * seq_length, 3, h, w)\n",
    "        features = self.resnet(x)\n",
    "        features = features.view(batch_size, seq_length, -1)\n",
    "        # Прогоняем RNN\n",
    "        #print(features)\n",
    "        rnn_out, _ = self.rnn(features)\n",
    "        # Получаем последний выход RNN и применяем полносвязный слой для классификации\n",
    "        output = self.fc(rnn_out[:, -1, :])\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ae3eee99789660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:41:46.903939Z",
     "start_time": "2024-02-18T14:41:46.627915500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# TODO Подбор архитектуры, функции ошибки и оптимайзера........\n",
    "model = CNN_RNN(2, rnn_hidden_size=8)\n",
    "model = nn.DataParallel(model, device_ids = [ 0, 1, 2, 3]).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.9), eps=1e-08, weight_decay=0.0001)\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf1d30085cfac4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-18T14:41:47.644086Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='training2.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if i % 10 == 9:  \n",
    "            logging.info('[%d, %5d] loss: %.7f accuracy: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, correct / total))\n",
    "            # TODO добавить данные в борд \n",
    "            writer.add_scalar('Training Loss', running_loss / 100, epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Training Accuracy', correct / total, epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = correct / total\n",
    "        logging.info('Accuracy of the network on the test images: %.3f' % (test_accuracy))\n",
    "        writer.add_scalar('Test Accuracy', test_accuracy, epoch)\n",
    "        \n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            logging.info('Model saved with accuracy: %.3f' % (best_accuracy))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94a88bd2a39a74",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148281d29e6a68e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
